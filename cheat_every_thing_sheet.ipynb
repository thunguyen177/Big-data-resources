{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "cheat every thing sheet.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyNocRfUF+jZLhU/BW6pCkYH",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/thunguyen177/Big-data-resources/blob/master/cheat_every_thing_sheet.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YbQ9a0eSLWRc",
        "colab_type": "text"
      },
      "source": [
        "- **Download & extract data**:\n",
        "download and extract: `tf.keras.utils.get_file()` or \n",
        "```\n",
        "import tensorflow_datasets as tfds\n",
        "\n",
        "dl_manager = tfds.download.DownloadManager\n",
        "train_dir = dl_manager.download_and_extract('https://abc.org/train.tar.gz')\n",
        "```\n",
        "\n",
        " Parallel download: list -> list\n",
        "```\n",
        "image_files = dl_manager.download(\n",
        "    ['https://a.org/1.jpg', 'https://a.org/2.jpg', ...])\n",
        "```\n",
        " Parallel download: dict -> dict\n",
        "```\n",
        "data_dirs = dl_manager.download_and_extract({\n",
        "   'train': 'https://abc.org/train.zip',\n",
        "   'test': 'https://abc.org/test.zip',\n",
        "})\n",
        "data_dirs['train']\n",
        "data_dirs['test']\n",
        "```\n",
        "- **Preprocessing data**: \n",
        "\n",
        "`train_df = tf.data.Dataset.from_tensor_slices((Xtrain, ytrain)).shuffle(TRAIN_BUF).batch(BATCH_SIZE)`\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7qTyKgrCAGUf",
        "colab_type": "text"
      },
      "source": [
        "- **Checkpoint**:\n",
        "\n",
        "```\n",
        "def scheduler(epoch):\n",
        "  if epoch < 40:\n",
        "    return 0.001\n",
        "  else:\n",
        "    return 0.0005\n",
        "\n",
        "callback = tf.keras.callbacks.LearningRateScheduler(scheduler)\n",
        "checkpoint_path = \"cp.ckpt\"\n",
        "checkpoint_dir = os.path.dirname(checkpoint_path)\n",
        "\n",
        "# Create a callback that saves the model's weights\n",
        "cp_callback = tf.keras.callbacks.ModelCheckpoint(filepath=checkpoint_path,\n",
        "                                                 monitor = 'loss',\n",
        "                                                 save_best_only = True,\n",
        "                                                 save_weights_only=True,\n",
        "                                                 verbose=1)\n",
        "\n",
        "cp_callback = tf.keras.callbacks.EarlyStopping(monitor = 'val_loss',\n",
        "                                               patience = 100,\n",
        "                                               restore_best_weights = True)\n",
        "\n",
        "history = model.fit(X_train, y_train,\n",
        "                    batch_size = BATCH_SIZE,\n",
        "                    epochs=EPOCHES,\n",
        "                    callbacks=[callback,cp_callback]) \n",
        "```\n",
        "- **loading weights from check points**:\n",
        "```\n",
        "checkpoint_path = \"drive/My Drive/Colab Notebooks/checkpoints_conv/cp.ckpt\"\n",
        "model.load_weights(checkpoint_path)\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OIWiczkHLppk",
        "colab_type": "text"
      },
      "source": [
        "## Functions:\n",
        "\n",
        "- `@tf.function`: decorator to run function as a tensorflow graph\n",
        "\n",
        "- `tf.map_fn`: map function to a vector. **super slow**\n",
        "\n",
        "- `tf.vectorized_map`: Parallel map on the list of tensors unpacked from elems on dimension 0. (does not allow index mapping. For index mapping, use python built in `map()` instead)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lXGYAEmyIWuG",
        "colab_type": "text"
      },
      "source": [
        "## Gradient\n",
        "\n",
        "- **Gradient clipping**: \n",
        "\n",
        "`tf.clip_by_value`\n",
        "\n",
        "`tf.clip_by_norm`\n",
        "\n",
        "`tf.clip_by_global_norm` \n",
        "\n",
        "```\n",
        "  with tf.GradientTape() as tape:\n",
        "    loss = compute_loss(model, x,y)\n",
        "  gradients = tape.gradient(loss, model.trainable_variables)\n",
        "  # gradients, _ = tf.clip_by_global_norm(gradients, 5.0)\n",
        "  gradients = [tf.clip_by_value(gr, 0.0001,1) for gr in gradients]\n",
        "  optimizer.apply_gradients(zip(gradients, model.trainable_variables))\n",
        "```\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OMFEDUvDBMqi",
        "colab_type": "text"
      },
      "source": [
        "## Colab"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7ThhfOduBki-",
        "colab_type": "text"
      },
      "source": [
        "- **Download data directly**:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4WhGjW-kBpAo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# raw=true is important so you download the file rather than the webpage.\n",
        "!wget https://github.com/snagcliffs/PDE-FIND/blob/master/Datasets/kuramoto_sivishinky.mat?raw=true\n",
        "# rename the file\n",
        "!mv kuramoto_sivishinky.mat\\?raw\\=true kuramoto_sivishinky.mat\n",
        "# For zipped files\n",
        "!wget https://archive.ics.uci.edu/ml/machine-learning-databases/00433/Flowmeters.zip\n",
        "!unzip Flowmeters.zip"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YG_i_oXVCTty",
        "colab_type": "text"
      },
      "source": [
        "- **connect with drive**\n",
        "```\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "```\n",
        "- **Upload file**:\n",
        "```\n",
        "from google.colab import files\n",
        "uploaded = files.upload()\n",
        "```\n",
        "- **Download files**:\n",
        "```\n",
        "from google.colab import files\n",
        "files.download('checkpoint')\n",
        "files.download('cp.ckpt.data-00000-of-00001') \n",
        "files.download('cp.ckpt.index')\n",
        "```\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5jixc7QMyNSo",
        "colab_type": "text"
      },
      "source": [
        "## Tensorflow adds on\n",
        "```\n",
        "import tensorflow_addons as tfa\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xKrcE1czutO1",
        "colab_type": "text"
      },
      "source": [
        "## Pandas\n",
        "- It's possible to use `pop()` with column numbers. Ex: `df.pop(48)` to get the 48th column"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-82qG8n2Q2U8",
        "colab_type": "text"
      },
      "source": [
        "## set random seed\n",
        "\n",
        "```\n",
        "from numpy.random import seed\n",
        "seed_value = 0\n",
        "tf.random.set_seed(0)\n",
        "# 1. Set `PYTHONHASHSEED` environment variable at a fixed value\n",
        "import os\n",
        "os.environ['PYTHONHASHSEED']=str(seed_value)\n",
        "\n",
        "# 2. Set `python` built-in pseudo-random generator at a fixed value\n",
        "import random\n",
        "random.seed(seed_value)\n",
        "\n",
        "# 3. Set `numpy` pseudo-random generator at a fixed value\n",
        "np.random.seed(seed_value)\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "riAB7FzKIr7f",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vz-A7S6LKIsR",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "<script type=\"text/javascript\" src=\"//s7.addthis.com/js/300/addthis_widget.js#pubid=ra-5cf9633718532342\"></script>\n",
        "<div class=\"addthis_inline_share_toolbox\"></div>\n",
        "    <div id=\"fb-root\"></div>\n",
        "<script async defer crossorigin=\"anonymous\" src=\"https://connect.facebook.net/en_GB/sdk.js#xfbml=1&version=v3.3\"></script>\n",
        "<div class=\"fb-comments\" data-href=\"https://ellienguyen.style/aii/index.html\" data-width=\"\" data-numposts=\"5\"></div>\n",
        "    <footer id=\"main-footer\">\n",
        "        <hr color = \"black\" width=\"400px\">\n",
        "            \t\tCopyright &copy; 2019 Ellie Nguyen. All rights reserved.\n",
        "\t</footer>\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ygfIo8_PKKD5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}